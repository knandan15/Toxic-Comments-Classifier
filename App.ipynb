{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st \n",
    "import numpy as np \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer \n",
    "import pickle\n",
    "\n",
    "#for BERT\n",
    "import pandas as pd\n",
    "import argparse\n",
    "import os\n",
    "from detoxify import Detoxify\n",
    "\n",
    "st.title('TOXIC COMMENTS CLASSFIER')    \n",
    "\n",
    "st.write(\"\"\"\n",
    "# Explore different classifiers\n",
    "\"\"\")\n",
    "\n",
    "user_input = st.text_input('\\nEnter Comment: ')\n",
    "\n",
    "\n",
    "classifier_name = st.sidebar.selectbox(\n",
    "    'Select classifier',\n",
    "    ('Random Forest', 'BERT','Multilingual')\n",
    ")\n",
    "#BERT CODE\n",
    "def predict_bert(model_name,user_input):\n",
    "    \"\"\"Loads model from checkpoint or from model name and runs inference on the input_obj.\n",
    "    Displays results as a pandas DataFrame object.\n",
    "    If a dest_file is given, it saves the results to a txt file.\n",
    "    \"\"\"\n",
    "    text = [user_input]\n",
    "    if model_name is not None:\n",
    "        res = Detoxify(model_name).predict(text)\n",
    "    # else:\n",
    "    #     res = Detoxify(checkpoint=from_ckpt).predict(text)\n",
    "\n",
    "    res_df = pd.DataFrame(res, index=[text] if isinstance(text, str) else text).round(5)\n",
    "    print(res_df)  \n",
    "    return res\n",
    "\n",
    "# RF CODE \n",
    "# Load the TF-IDF vocabulary specific to the category\n",
    "if classifier_name=='Random Forest':\n",
    "    with open(r\"toxic_vect.pkl\", \"rb\") as f:\n",
    "        tox = pickle.load(f)\n",
    "\n",
    "    with open(r\"severe_toxic_vect.pkl\", \"rb\") as f:\n",
    "        sev = pickle.load(f)\n",
    "\n",
    "    with open(r\"obscene_vect.pkl\", \"rb\") as f:\n",
    "        obs = pickle.load(f)\n",
    "\n",
    "    with open(r\"insult_vect.pkl\", \"rb\") as f:\n",
    "        ins = pickle.load(f)\n",
    "\n",
    "    with open(r\"threat_vect.pkl\", \"rb\") as f:\n",
    "        thr = pickle.load(f)\n",
    "\n",
    "    with open(r\"identity_hate_vect.pkl\", \"rb\") as f:\n",
    "        ide = pickle.load(f)\n",
    "\n",
    "    # Load the pickled RDF models\n",
    "    with open(r\"toxic_model.pkl\", \"rb\") as f:\n",
    "        tox_model = pickle.load(f)\n",
    "\n",
    "    with open(r\"severe_toxic_model.pkl\", \"rb\") as f:\n",
    "        sev_model = pickle.load(f)\n",
    "\n",
    "    with open(r\"obscene_model.pkl\", \"rb\") as f:\n",
    "        obs_model  = pickle.load(f)\n",
    "\n",
    "    with open(r\"insult_model.pkl\", \"rb\") as f:\n",
    "        ins_model  = pickle.load(f)\n",
    "\n",
    "    with open(r\"threat_model.pkl\", \"rb\") as f:\n",
    "        thr_model  = pickle.load(f)\n",
    "\n",
    "    with open(r\"identity_hate_model.pkl\", \"rb\") as f:\n",
    "        ide_model  = pickle.load(f)\n",
    "\n",
    "def predict_rf(cmmt):\n",
    "    \n",
    "    # Take a string input from user\n",
    "    #user_input = request.form['text']\n",
    "    data = [cmmt]\n",
    "\n",
    "    vect = tox.transform(data)\n",
    "    pred_tox = tox_model.predict_proba(vect)[:,1]\n",
    "\n",
    "    vect = sev.transform(data)\n",
    "    pred_sev = sev_model.predict_proba(vect)[:,1]\n",
    "\n",
    "    vect = obs.transform(data)\n",
    "    pred_obs = obs_model.predict_proba(vect)[:,1]\n",
    "\n",
    "    vect = thr.transform(data)\n",
    "    pred_thr = thr_model.predict_proba(vect)[:,1]\n",
    "\n",
    "    vect = ins.transform(data)\n",
    "    pred_ins = ins_model.predict_proba(vect)[:,1]\n",
    "\n",
    "    vect = ide.transform(data)\n",
    "    pred_ide = ide_model.predict_proba(vect)[:,1]\n",
    "\n",
    "    return pred_tox[0], pred_sev[0], pred_obs[0], pred_thr[0], pred_ins[0], pred_ide[0]\n",
    "\n",
    "if classifier_name=='Random Forest':\n",
    "    if user_input=='':\n",
    "        t1,t2,t3,t4,t5,t6=[0,0,0,0,0,0]\n",
    "    else:\n",
    "        t1,t2,t3,t4,t5,t6 = predict_rf(user_input)\n",
    "    st.write('Toxic: ',t1)\n",
    "    st.write('Severe Toxic: ',t2)\n",
    "    st.write('Obscene: ',t3)\n",
    "    st.write('Insult: ',t4)\n",
    "    st.write('Threat: ',t5)\n",
    "    st.write('Identity Hate: ',t6)\n",
    "    df = pd.DataFrame({\n",
    "  'date': ['Toxic','Severe Toxic', 'Obscene', 'Threat','Insult','Identity Threat'],\n",
    "  'second column': [t1, t2, t3, t4,t5,t6]\n",
    "    })\n",
    "    df = df.rename(columns={'date':'index'}).set_index('index')\n",
    "    st.bar_chart(df)\n",
    "\n",
    "elif classifier_name=='BERT':\n",
    "    res_bert=predict_bert('original',user_input)\n",
    "    st.write('Toxic: ',res_bert[\"toxicity\"][0])\n",
    "    st.write('Severe Toxic: ',res_bert[\"severe_toxicity\"][0])\n",
    "    st.write('Obscene: ',res_bert[\"obscene\"][0])\n",
    "    st.write('Insult: ',res_bert[\"threat\"][0])\n",
    "    st.write('Threat: ',res_bert[\"insult\"][0])\n",
    "    st.write('Identity Hate: ',res_bert[\"identity_hate\"][0])\n",
    "    #graph_bert={'Toxic':res_bert[\"toxicity\"][0],'Severe Toxic':res_bert[\"severe_toxicity\"][0],'Obscene':res_bert[\"obscene\"][0],'Threat':res_bert[\"threat\"][0],'Insult':res_bert[\"insult\"][0],'Identity Hate':res_bert[\"identity_hate\"][0]}\n",
    "    df = pd.DataFrame({\n",
    "  'date': ['Toxic','Severe Toxic', 'Obscene', 'Threat','Insult','Identity Threat'],\n",
    "  'second column': [res_bert[\"toxicity\"][0], res_bert[\"severe_toxicity\"][0], res_bert[\"obscene\"][0], res_bert[\"threat\"][0],res_bert[\"insult\"][0],res_bert[\"identity_hate\"][0]]\n",
    "    })\n",
    "\n",
    "    df = df.rename(columns={'date':'index'}).set_index('index')\n",
    "    st.bar_chart(df)\n",
    "    \n",
    "elif classifier_name=='Multilingual':\n",
    "    res_bert=predict_bert('multilingual',user_input)\n",
    "    st.write('Toxicity: ',res_bert[\"toxicity\"][0])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!streamlit run app.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
